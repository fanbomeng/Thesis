
\chapter{Datasets}
\section{Datasets used in LFV analysis}
\subsection{\Hmuhad}
The dataset analyzed in the $\Hmuhad$ decay channel is collected by CMS detector during LHC 2016 operation. The total integrated luminosity of the analyzed dataset is $35.9 ~\textrm{fb}^{-1} $ at a center-of-mass energy of $ \sqrt{s}=13 ~\textrm{TeV} $. The dataset in which each event has at least one muon is used. It is selected by the trigger system. The ggH~\cite{Georgi:1977gs} and VBF~\cite{Cahn:1986zv} production are the main Higgs production channels considered in the analysis. For the background samples, besides the misidentified background which is discussed more in detail in Chapter 6, the other background samples are all generated with the Monte Carlo(MC) simulation. The POWHEG~\cite{POWHEG-BOX} are MadGraph~\cite{Alwall:2014} generator are used for the generation and all of the MC samples, including the signal samples, the parton showering, fragmentation, and decays are performed by Pythia8~\cite{Sjostrand:2014zea}.  The pileup effect is taking into account by generating minimum bias events. The average number of pileup interaction per bunch crossing is 27 in 2016. The CMS detector environment is simulated by GEANT4~\cite{GEANT4}. The details of the MC samples used in the analysis are summarized in Table.~\ref{tab:mutaumcsamples} and Table.~\ref{tab:mutaumcsamples2}.

\begin{table}[!hbpt]
\caption{Monte Carlo samples used in the $\Hmuhad$ search, together with their respective cross sections.}
\begin{center}
% sample name   &    generator    & cross section 
\begin{tabular}{|c|c|c|}
\hline
Processes & Generator & Cross section [pb] \\\hline
DYJets$\to\ell \ell$, $m_{\ell \ell}>50$ GeV &MadGraph+pythia8   & 4954.0 \\\hline
DY1Jets$\to\ell \ell$, $m_{\ell \ell}>50$ GeV &MadGraph+pythia8 & 1012.5 \\\hline
DY2Jets$\to\ell \ell$, $m_{\ell \ell}>50$ GeV&MadGraph+pythia8  & 332.8 \\\hline
DY3Jets$\to\ell \ell$, $m_{\ell \ell}>50$ GeV&MadGraph+pythia8  & 101.8 \\\hline
DY4Jets$\to\ell \ell$, $m_{\ell \ell}>50$ GeV&MadGraph+pythia8  & 54.8 \\\hline
DYJets$\to\ell \ell$, $m_{\ell \ell}<50$ GeV&MadGraph+pythia8    & 1861.0 \\\hline
$t\bar{t}$                                                     & powheg+PYTHIA     &  831.76\\\hline
$t \backslash \bar{t}\to t w$                        & powheg+PYTHIA8     &  35.85 \\\hline
$WZ \to \ell 3v$                                          & MadGraph+PYTHIA8   &  3.05   \\\hline
$WZ \to \ell v 2q $                                      & MadGraph+PYTHIA8   &  10.71  \\\hline
$WZ \to 2 \ell 2q $                                      &  MadGraph+PYTHIA8  &  5.595 \\\hline
$t\to4f $                                                     & POWHEG+PYTHIA8       & 136.02\\\hline
$\bar{t}\to4f $                                             & POWHEG+PYTHIA8       & 80.95\\\hline
$WW \to \ell v 2q$                                      & MadGraph+PYTHIA8   &  1.212   \\\hline
$ZZ \to 2\ell 2q $                                        & MadGraph+PYTHIA8    &  3.22   \\\hline
$VV \to2\ell 2 q$                                        &  MadGraph+PYTHIA8   &  11.95  \\\hline

\end{tabular}
\end{center}
\label{tab:mutaumcsamples}
\end{table}

\begin{table}[!hbpt]
\caption{Continue with MC samples used in the analysis.}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
MC simulations & Generator & Cross section [pb] \\\hline
$VV \to2\ell 2 q$                                        &  MadGraph+PYTHIA8   &  11.95  \\\hline
$ggH\to \Pgt\Pgt $                                      & POWHEG+PYTHIA8 &      3.046\\\hline
$\textrm{VBF}H\to \Pgt\Pgt $                     & POWHEG+PYTHIA8 &      0.237\\\hline
$ggH\to WW \to 2\ell 2v$                            & POWHEG+PYTHIA8 &      1.103\\\hline
$\textrm{VBF}H\to WW\to 2\Pl 2v$             & POWHEG+PYTHIA8 &    0.086\\\hline
$ZH \to \Pgt\Pgt$                                        & POWHEG+PYTHIA8 &    0.055\\\hline  
$W^{-}\backslash W^{+} H\to\Pgt\Pgt$        & POWHEG+PYTHIA8 &    0.086\\\hline 
$ttHJet \to \Pgt\Pgt$                                   &MadGraph+PYTHIA8&     0.32\\\hline   
\end{tabular}
\end{center}
\label{tab:mutaumcsamples2}
\end{table}


\subsection{\Hehad}

The search for lepton flavour violation Higgs decay $\Hehad$  is performed with CMS 2012 RunI dataset at a center-of-mass energy  $\sqrt{s}=8 ~\textrm{TeV}$ with an integrated luminosity of $19.7 ~\textrm{fb}^{-1}$. In each of the events in the dataset, at least one electron is required, which is selected by the single electron trigger. More details about the this trigger is discussed in details in the Chapter 5. A detail list of simulation samples used in the analysis is in Table.~\ref{tab:mcdatasets}.  For the signal samples, the ggH and VBF Higgs production channels are the channels considered. For the background samples, besides the $Z\to \tau \tau$ which is produced with the embedding technique and the misidentified background which is estimated with the data-driven method are produced with Monte Carlo simulation. Various simulation packages are used. Signal samples are produced with PYTHIA8, which uses sophisticated $\tau$-lepton decay machinery. The Tauola~\cite{Simulation:Tauola} package is also used for the simulation of $\tau$ lepton decay in some of samples. The CMS detector environment is simulated by GEANT4. 


\begin{table}[hbtp]
 \begin{center}
  \caption{Signal and background MC samples}
  \label{tab:mcdatasets}
  \begin{tabular}{l|l|l}
Processes & Generator & Cross section [pb] \\\hline
$ggH\to e\tau $     &          PYTHIA8                     &  19.27                \\\hline
$VBH\to e\tau$     &          PYTHIA8                      &   1.58                \\  \hline
$ggH \to \tau\tau$ &POWHEG+PYTHIA6              &  19.27           \\\hline
 $VBF\to\tau\tau$  &POWHEG+PYTHIA6              &   1.58           \\  \hline
$t\overline{t}+\textrm{jets}~ \textrm{full}~\textrm{leptonic}$  &  MadGraph+Tauola                &  26.20                \\\hline
$t\overline{t}+\textrm{jets}~\textrm{Semi}~\textrm{leptonic}$   & MadGraph+Tauola           &  109.28               \\ \hline
$t \to tw$              &   POWHEG+Tauola     &    56.4 \\\hline
$\bar{t} \to tw$              &   POWHEG+Tauola     &    30.7 \\\hline
$t$,$\bar{t}(\textrm{T channel})$           & POWHEG+Tauola        &   11.1 (11.1)          \\ \hline
$WW \to 2l2\nu+jets$    & PYTHIA6+Tauola                  & 5.824\\ \hline
$ZZ\to 4l$               & MadGraph+Tauola                 & 0.18                  \\  \hline
$ZZ\to 2l2Q$             &MadGraph+Tauola              &   2.502               \\  \hline
$ZZ\to 2l2\nu$           &MadGraph+Tauola              &    0.716              \\  \hline
$WZ\to 2l2Q$             &MadGraph+Tauola                &    2.21               \\  \hline
$WZ\to 3l\nu$            &MadGraph+Tauola           & 1.06                  \\  \hline
  \end{tabular}
 \end{center}
\end{table}





\section{Event reconstruction}
In this section, a general presentation of the event reconstruction algorithm used in CMS, the particle-flow(PF) reconstruction is shown. The focus is the particles and objects that are directly related the physics searches in the dissertation. More detail information of the reconstruction of tracks and the objects  used in the physics analyses in CMS can be found in~\cite{CMS-PRF-14-001}.  
\subsection{Particle flow algorithm}

The particle flow event reconstruction algorithm is the main algorithm used in CMS. The PF performs a global event reconstruction, which aims to utilize the information from the whole detector to identify individual particles in each of the events.



\subsubsection{Tracking and Calorimeter algorithm}\label{PFtracker}

In the PF algorithm, the reconstruction of charged particles in the inner tracker is crucial. In this section, the reconstruction of the trajectories of charged particles, especially the electron and muon reconstruction are discussed. 

The inner tracker aims at measuring the tracks of energetic charged particles. The track finder is based on the Kalman Filtering(KF) algorithm~\cite{tracker:algo} which performs the reconstruction in several steps. First an initial seed is generated from a couple hits that compatible with a track in the tracker, then a trajectory is builded with the seed and other hits inside the tracker along this track. At last a fit is perform on the track  to determine the properties of this particle candidate, like the momentum and the electric charge. Several qualities can affect the performance of the reconstruction, for example,  the number of hits in the pixel detector, the total number of hits in the tracker, the distance from the cylinder and the energy of this charged particle. 

The performance of the track reconstruction is measured in reconstruction efficiency and misreconstruction rate. The reconstruction efficiency is defined as the ratio between the tracks reconstructed with more than 50\% of the simulated hits from the MC sample and the total simulated tracks. The misreconstruction rate is defined as the fraction of the tracks that can not be associated with simulated tracks within the MC sample.  If a charged hadron is not identified by the tracking algorithm, then the hadron is take as a neutral hadron and measured by the calorimeters. This will affect the jet energy and position resolution. Improving the track reconstruction efficiency while keeping the misreconstructed rate low is critical for the PF reconstruction.

In CMS, an iterative tracking is perform, in which the reconstruction of tracks is done in a couple of steps. Each step aims for a moderate efficiency but with a high purity. After one step, the hits that are used to form tracks are masked and a next step is performed. This iterative tracking is down in ten steps if necessary and the detail information is shown in Table.~\ref{tbl:iterative_tracking} and more can be found in \cite{CMS-PRF-14-001}. In the table, the name column points out the processes that this iteration step aims at. The seeding column shows the requirement on the seeding, while the targeted track column shows the characters of the tracks.

Electrons are one of the main particles understudy in $\Hehad$ search. In CMS, the reconstruction of electron track is taken as a merge of the ECAL based and tracker based strategy. The tracker based seeding strategy is as described above, then a preselection based on the number of hits and $\chi^{2}$ of the fit is set with the Gaussian-sum filter~\cite{Algo:GSF}. The ECAL based electron seeding strategy builds the superclusters(SC) to gather the bremsstrahlung photons. The energy of the SC is taken as the energy sum of the cell crystals inside and the position is evaluated with the weight that is related to the energy distribution. The electron trajectory in the first layer of the tracker is estimated and the seed from the track is selected. This works in the case when there is not much bremsstrahlung photons and most of the energy is deposited in ECAL. In the case when soft photons are radiated mostly, the ECAL based seeding performs better. But when the electrons are in the jets or of low energy, either electron contributions are overlapping with other particles or the radiation and the bending is too much, it is hard to recover these electrons with ECAL based algorithm only. The ECAL based and tracker based electron seeding is merged into one collection, which significantly improves the reconstruction efficiency.



\begin{table}[!tpb]
\caption{Iterative tracking steps taken in CMS \label{tbl:iterative_tracking}}
\label{tab:antil}
\begin{center}
\begin{tabular}{|llll|}   
\hline
Iteration                   &  Name               &   Seeding            &  Targeted Tracks  \\\hline
1                              & InitialStep          & pixel triplets        &  prompt, high $p_{t}$   \\
2                              & DetachedTriplet          & pixel triplets        &  from b hadron decays, R$\lesssim$ 5 cm  \\
3                              & LowPtTriplet          & pixel triplets        &  prompt, low $p_{t}$ \\
4                              & PixelPair          & pixel pairs                &  recover high $p_{t}$ \\
5                              & MixedTriplet          & pixel+strip triplets                &  displaced,  R$\lesssim$ 7 cm   \\
6                              & PixelLess          & strip triplets / pairs               &  very displaced, R$\lesssim$ 25 cm     \\
7                              & TobTec          & strip triplets / pairs               &  very displaced, R$\lesssim$ 60 cm     \\
8                              & JetCoreRegional          & pixel+strip pairs               &  inside high $p_{t}$ jets    \\
9                              & MuonSeededInOut          & muon-tagged tracks               &  muons   \\
10                            & MuonSeededOutIn          & muon detectors                &  muons   \\\hline
\end{tabular}
\end{center}
\end{table}


Calorimeters are crucial components for the PF algorithm in CMS. The clustering algorithms in the calorimeters are used to identify neutral stable particles like photon and neutral hadron. Together with the tracker, calorimeters are used in the identification of charged particles, reconstructing the energy of electrons and the possible associated bremsstrahlung photons and measuring the energy of charge particles that are missed by the tracker.  

The clustering algorithm is perform separately in each sub-detector system besides the HF in which each cell directly raise a cluster. The algorithm starts by finding a cluster seed. Then a topological walk around the neighbouring cells is performed. Both seed cells and neighbouring cells are required to pass certain thresholds to construct high quality candidates and suppress the contribution from the noise. In ECAL endcaps, there are additional requirements on $E_{T}$ because of the high noise level. In each of the topological clusters, the energy for the neighbouring cells are assumed from the same particle candidate. A Gaussian-mixture model is used in the construction of the topological clusters to evaluate the contribution of each cells. The finally parameters of the model are obtained by analytical fitting to the Gaussian model.

To accurately measure the energy of the particles like photons and neutral hadrons, the calibration of calorimeters is indispensable. The calibration of calorimeters also affects the identification efficiency and the misidentification rate of the particles measured by the calorimeters. The calibration of ECAL is done with a couple sources, like the test beam, the radioactive source and the cosmic ray measurements and is refined with the collision data. There are thresholds used in the formation of topological clusters, which makes the energy measured smaller than the incoming particle energy. A residual energy calibration is applied to all of the ECAL clusters to account for these affects.  The correction is applied as a function of cluster energy and position, $f(E,\eta)=g(E)h(\eta)$. In the endcaps, the energy of the measured particle is taken as a liner combination of the ECAL and preshower energy. The parameters in the combination are optimized by the $\chi^{2}$ method. Hadrons generally leave energy in both ECAL and HCAL. The calibration of ECAL mentioned above is for the photon and electron calibration. The behavior of hadron is different and a consequent calibration involving both ECAL and HCAL is needed. Simulated single neutral hadrons are used. The relationship involves both the energy measured by ECAL and HCAL and the calibrated energy $E_{calib}$ is expressed as

\begin{align*}
E_{calib}=a+b(E)f(\eta)E_{\textrm{ECAL}}+c(E)g(\eta)E_{\textrm{HCAL}}
\end{align*}

In the equation above, the coefficient "a" is independent of E and accounts for the effects of thresholds in the clustering algorithm. The other coefficients are determined by the $\chi^{2}$ optimization with the $E_{calib}$ and true energy E from simulation. 


\begin{figure}[htbp] 
\centering
\includegraphics[width=0.6\textwidth]{chapter4/CMS_detecter_slice.pdf}
\caption{A sketch view of CMS detecter. Examples are given to show how the particles interact with different sub-detecters.}
\label{fig:CMSslice}
\end{figure}



\subsection{Muon reconstruction and selection criteria}

The PF muon is used in the $\Hmuhad$ analysis. In CMS, the event reconstruction starts from building the tracks in tracker(tracker track) and muon system(standalone-muon track) separately. The global muon reconstruction and tracker muon reconstruction are based on these tracks~\cite{muonreco}. The global muon reconstruction starts from the standalone-muon tracks and requires at least two muon stations in the muon system. For each of the standalone-muon track, a propagating is done to find the matching tracker track on the common surface. The Kalman-filter technique~\cite{Fruhwirth:1987fm} is used in the fitting to combine the hits in standalone-muon track and tracker track. The tracker muon starts from the tracks with $\pt>0.5$ GeV and total momentum $p>2.5$ GeV. The tracks are then extrapolated to match the tracks in the muon system with at least one muon segment.  Within the geometry acceptance of muon system, the muon reconstruction efficiency is high, especially high momentum muons, constructed as either global muon or tracker muon or both have the  efficiency about 99\%. The muon PF algorithm applies a series of selections to the global muon and tracker muon to select out the PF muon. The selection is optimized to identify the muons in the jets with high efficiency and low misidentify rate. The details of the selection is in~\cite{PFmuonselection}.   



Taking the PF muon as the input, muons used in the analysis are further categorized into different identification(ID), isolation(Iso) categories. The loose muon ID refers to the muons selected by the PF algorithm. The medium Muon ID is suggested to use in CMS Run II data analysis. For the LHC 2016 running era, two muon medium IDs, with slight differences are applied according to different data taking period within 2016, the ICHEP medium muon ID(Table~\ref{tbl:ICHEPMedID}) to the running period G and H and the Monte Carlo samples, while the standard medium muon ID(Table~\ref{tbl:standardMedID}) to the remaining datasets. The muon isolation used in the analysis is calculated the same way as the electron isolation which is shown in the following electron section.

%In the compatibility-based selection, two ?compatibility? variables are constructed, one based on calorimeter information and the other based on information from the
%muon system. A tracker muon is considered to be a muon candidate if the value of a linear combination of these variables is larger than a pre-defined threshold.
%The segment compatibility, which can have values between 0 and 1, describes the quality of the spatial
%agreement between muon segments and the reconstructed track of the muon candidate


%The kink finder algorithm searches for an interaction of the studied particle with the layers of the
%tracking system by performing a fit of the section of the track before the layer with the one after the
%layer. If an interaction happened, the fit will not work properly because of a change in curvature of
%the track.



\begin{table}[!tpb]
\caption{Muon ID used in the analysis, for the LHC data 2016, running period BCDEF.  \label{tbl:ICHEPMedID}}
\label{tab:antil}
\begin{center}
\begin{tabular}{|l|c|}   
\hline
ICHEP mediumID description                    &  Technical description\\\hline
Loose muon ID                               & PFLoose Muon\\\hline
Fraction of valid tracker hits           & $>0.49$ \\\hline
\multirow{5}{*}{1.Good Global muon}                      &Global muon\\\cline{2-2}
                                                                        &Normalized global-track $\chi^{2}<3$\\\cline{2-2}
                                                                        &Tracker-Standalone position match $< 12$\\\cline{2-2}
                                                                        &kick finder $< 20$ \\\cline{2-2}
                                                                        &Segment compatibility $> 0.303$ \\\hline                                                                       
\hline
2. Tight segment compatibility      & Segment compatibility $>0.451$\\\hline
\end{tabular}
\end{center}
\end{table}


\begin{table}[!tpb]
\caption{Muon ID used in the analysis, for the LHC data 2016, running period G and H, also the monte Carlo samples.  \label{tbl:standardMedID}}
\label{tab:antil}
\begin{center}
\begin{tabular}{|l|c|}   
\hline
Standard mediumID description                    &  Technical description\\\hline
Loose muon ID                               & PFLoose Muon\\\hline
Fraction of valid tracker hits           & $>0.8$ \\\hline
\multirow{5}{*}{1.Good Global muon}                      &Global muon\\\cline{2-2}
                                                                        &Normalized global-track $\chi^{2}<3$\\\cline{2-2}
                                                                        &Tracker-Standalone position match $< 12$\\\cline{2-2}
                                                                        &kick finder $< 20$ \\\cline{2-2}
                                                                        &Segment compatibility $> 0.303$ \\\hline                                                                       
\hline
2. Tight segment compatibility      & Segment compatibility $>0.451$\\\hline
\end{tabular}
\end{center}
\end{table}


\subsection{Electron identification}

Electrons in CMS is constructed with the information from tracker and calorimeters. One of the main difficulties in the reconstruction is the bremsstrahlung energy emitted by the electron. The conversion of photons from the bremsstrahlung affects the reconstruction of tracks in the tracker and these photons also cause significance energy loose in the electron reconstruction. The reconstruction of electrons is covered in section~\ref{PFtracker}, which discusses the general tracker and calorimeters reconstruction. More details can be found in~\cite{electron_reco2015}. 

The electron ID is constructed to separate prompt isolated electron(signal) from the electrons presented in the background processes. The background can be the electrons from photon conversion, from quark semi-leptonic decay or from misidentification of other particles or jets. The variables used in the identification are related to tracker and ECAL.  There are mainly three types of variables. One type is the variables related only to calorimeters, for example, the cluster shape of real electron in ECAL is usually narrower than the shape from hardonic shower and electrons leave most of the energy in ECAL and the energy ratio between ECAL and HCAL is large. The variables related to the matching of measured energy and geometry between tracker and ECAL. The variables related to tracker fitting to explore the differences between electrons and hadrons. These related variables can be used to construct cut-based selection sequence to selection electron. To achieve better performance, the MVA based ID with boosted decision tree is also used. Comparing with the cut-based selection, more variables in the three categories mentioned above are used in the MVA training~\cite{electron_reco2015}.  An example of the BDT electron ID is shown in Figure.~\ref{fig:eleBDTID}. The discussion of the BDT method is presented in Chapter 7.


\begin{figure}[!htbp] 
     \centering
     \subfigure[EB]{ \includegraphics[width=0.4\textwidth]{chapter4/EleID_EB_BDT_perfor.pdf}}
     \subfigure[EE]{ \includegraphics[width=0.4\textwidth]{chapter4/EleID_EE_BDT_perfor.pdf}}\\
     \caption{The electron BDT-based ID shows good discriminating power against background in both EB and EE~\cite{electron_reco2015}}
     \label{fig:eleBDTID}
\end{figure}


The electron isolation is used to reject background events in addition to the ID variables, also inverting the requirement on the isolation can be used to setup enriched background control regions. A large numbers of background events that possiblely pass the signal selection are misidentified jets or the jets in which there are real electrons, for example the jets from b quark semi-leptonic decay. For these background events, one key different character with respect to signal events is more energy flowing around the electron(or misidentified electron) trajectories. The isolation requirement used in HLT level is summing over the energy depositions either in ECAL or HCAL in a certain core, for example $\Delta R=0.3,0.4$, $\Delta R=\sqrt{\Delta \phi^{2}+\Delta\eta^{2}}$. The contribution from the particle candidate is removed. In the offline algorithm, particles can better identified with the PF algorithm. The PF isolation summing over the $\pt$ of the particles in the direction of the reconstructed candidate trajectory momentum. The PF algorithm utilizes the whole detector information and the isolation is calculated as



\begin{equation}\label{Iso_correction}
%\textrm{Iso}_{\textrm{PF}}=\sum \pt^{\textrm{charged}}+\textrm{max}\bigg[ 0,\sum \pt^{\textrm{neutral~had}} +\sum \pt^{\gamma}-\pt^{\textrm{PU}}\bigg]
\textrm{Iso}_{\textrm{PF}}=\sum \pt^{\textrm{charged}}+\textrm{max}\bigg[ 0,\sum \pt^{\textrm{neutral~had}} +\sum \pt^{\gamma}-\frac{1}{2}\sum\pt^{\textrm{charged,PU}}\bigg]
\end{equation}
The isolation variable sums over the contribution from charged PF candidates, neutral particles and photons in the selected certain $\Delta R$ region around the signal candidate. The contribution from pileup is estimated with the $\Delta \beta$ correction in the last term of Equation.~\ref{Iso_correction}. The factor 0.5 comes from the naive measurement of neutral to charged particles in jets~\cite{FastJetalso}. The energy of PF objects are better calibrated and the possibly double counting is taken cared of. The PF isolation variable performs better than the isolation variable used in HLT. The performance comparison is shown in Figure.~\ref{fig:eleIso}

\begin{figure}[!htbp] 
     \centering
     \subfigure[EB]{ \includegraphics[width=0.4\textwidth]{chapter4/ROC_IsoOnly_Data_EB_HighPt.png}}
     \subfigure[EE]{ \includegraphics[width=0.4\textwidth]{chapter4/ROC_IsoOnly_Data_EE_HighPt.png}}\\
     \caption{The PF electron isolation shows better performance in both EB and EE with respect to detector based isolation variable~\cite{electron_reco2015}}
     \label{fig:eleIso}
\end{figure}




\subsection{Tau lepton reconstruction} \label{Chapter:taureco}

In CMS Run I period, tau leptons are constructed with hadrons plus strips(HPS) algorithm. In general, the HPS starts with PF jets which are reconstructed with $Anti-k_{T}$ algorithm~\cite{Cacciari:2008gp}, as the initial seeds. The $\pi_{0}$ components from the $\tau$ hadronic decays are first constructed and combined with the charge hadrons parts, to identify different $\tau$ decay modes and calculate $\tau$ four-momentum and other quantities~\cite{TauIdentiRunI}. The $\tau$ decay modes is discussed in the later part of this section.

Photon conversions and the bremsstrahlung of electron/positron when travel inside the CMS detector are well treated by the HPS algorithm. These phenomenons broaden the signature of the tau decay. Taking PF jets as input, the algorithm constructs strips out of electromagnetic particles and starts by taking the strip(0.05 in $\eta$ and 0.2 in $\phi$) in which contains the most energetic electromagnetic particle as the center one. Within this strip window, if other charged particles are found, they are associated with this strip. The position of the strip is taken and four momentum of the strip is calculated. This procedure is repeated, until no strips can be constructed. The selected strips are required to have $P_{T}^{strip}>1$ GeV. The following decay topologies are taking into account by the HPS:
\begin{enumerate}[$\bullet$]
\item one charged particle without any strip, $h^{\pm}$ and the case when $\pi^{0}$ is not energetic enough to form a strip
\item one charged particle plus one strip
\item one charged particle plus two strips
\item three charged partibles. 
\end{enumerate} 

All of the charged hadrons and strips are required to be contained in the $\Delta R=2.8/P_{T}^{\tau_{h}}$ core, where the $P_{T}^{\tau_{h}}$ is the reconstructed $\tau_{h}$ transverse momentum and $\Delta R$ is defined as $\Delta R=\sqrt(\Delta \phi^{2}+\Delta \eta^{2})$. The $\tau_{h}$ candidate is also required to match the direction of the seed PF jet within $\Delta R=0.1$. Assuming all of the charged hadrons to be pions and taking in the associated strips, the HPS algorithm requires that different decay topologies meet the intermediate meson mass requirments as listed in Table.~\ref{tb:tauHdecay}. 

The cut based $\tau_{h}$ isolation discriminant requires that the PF charged particles and photons to be considered in the isolation variable have $\pt>0.5$ GeV and within the isolation cone  $\Delta R=0.5$ in $\tau_{h}$ direction. The particles that  constituent $\tau_{h}$ are excluded from the summation. The effect of charged particles from the pileup is eliminated by considering the charged particle oriented from the $\tau_{h}$ production vertex with in $D_{z}=0.2$ cm and $\Delta r=0.03$ cm. The effect of pileup on the isolation of the photons on the strips is estimated by summing the charged particles that are not oriented from $\tau_{h}$ decay primary vertex, within $\Delta R=0.8$ in the direction of $\tau_{h}$ and have the impact parameter $D_{z}>0.2$ cm. Then a factor $\Delta \beta$ is multiplied to the $\pt$ sum. The isolation variable is calculated as in Equation.~\ref{eq:taucutiso1}.

\begin{align}
I_{\tau}=\sum \pt^{\text{charged}} (d_{z}<0.2 \ \text{cm})+\text{max}(0,\sum \pt^{\gamma}-\Delta \beta \sum \pt^{\text{charged}} (d_{z}>0.2 \ \text{cm}))\label{eq:taucutiso1}
\end{align}

The tight, medium and loose working points(WP) are the tau isolation discriminants. The exact energy selection in the isolation discriminants is suggested by the study of QCD dijet events, by requiring the $I_{\tau}$ in Equation.~\ref{eq:taucutiso1} to have different values. The loose cut brings in approximate $1\%$ of fake $\tau$ from jets~\cite{TauIdentiRunI}. 


\begin{table}[htp]
\caption{Dominant hadronic $\tau$ lepton decays branching fractions and the associated intermediate resonance. The h stands for both $\pi$ and K. The table is symmetric under charge conjugation.}\label{tb:tauHdecay}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Decay mode                                             & Resonance & Mass ($MeV/c^{2}$) & Branching fraction(\%)\\\hline
$\tau^{-}\to h^{-}v_{\tau}$                                     &                                  &           &  11.6\%     \\
$\tau^{-}\to h^{-}\pi^{0} v_{\tau}$                       & $\rho^{-}$                 & 770     &   26.0\%      \\
$\tau^{-}\to h^{-}\pi^{0} \pi^{0}  v_{\tau}$       & $\alpha_{1}^{-}$       & 1200   &   9.5\%     \\
$\tau^{-}\to h^{-}h^{+}h^{-}v_{\tau}$                     & $\alpha_{1}^{-}$       &  1200  &   9.8\%  \\
$\tau^{-}\to h^{-}h^{+}h^{-}\pi^{0} v_{\tau}$      &                                  &            &   4.8\% \\\hline
 \end{tabular}
\end{center}
\end{table}


In CMS Run II, the tau reconstruction algorithm HPS has been improved~\cite{TauRecoandIDRunII}. The major improvement lies in dynamic strip instead of fix size strip. Tau decay products can also affect the isolation. The charged pions in tau decay products experience nuclear interaction with tracker materials, which can result in low $P_{T}$ secondary particles. The photons from the neutral pion decays can also go through pair production into $e^{+}e^{-}$, which further spread because of the bremsstrahlung and the magnetic field. Broadening the strip is need in these cases in order to better cover the tau decay production. On the other hand, if the tau is boosted, high $P_{T}$ decay products tend to be more concentrated and the smaller strip size is better. Similar to RunI tau reconstruction, the algorithm starts with hightest $\pt$ charged particle as seeds for the strip. Starting from the seed strip, a window in $\eta$ and $\phi$ direction is set.  

\begin{align*}
\delta\eta&=f(P_{T}^{\gamma})+f(P_{T}^{strip})   & f(P_{T})&=0.2\cdot P_{T}^{-0.66}\\
\delta\phi&=g(P_{T}^{\gamma})+g(P_{T}^{strip}) & g(P_{T})&=0.35\cdot P_{T}^{-0.71}\\
\end{align*}

The window is determined from single $\tau$ gun MC simulation. 95\% of the decay products will be covered in that range. The upward and downward limit for $\eta$ is 0.15 and 0.05. In the $\phi$ direction, the range is 0.3 and 0.05.  The position of strip is set as $\pt$ weighted average against all of the objects. 

\begin{align*}
\eta_{strip}&=\frac{1}{P_{T}^{strip}}\cdot\sum P_{T}^{\gamma}\cdot\eta_{\gamma}\\
\phi_{strip}&=\frac{1}{P_{T}^{strip}}\cdot\sum P_{T}^{\gamma}\cdot\phi_{\gamma}\\
\end{align*}

The construction of the strips continues until no seed strip can be construced. After the construction of the $\tau$ lepton, for different decay mode, the $m_{\tau}$ is required to lie in different mass windows~\cite{TauReconstuction}.  The conditions of different hadronic decay mode mass windows are listed in the Table.~\ref{tb:tauHdecayRecomass}. Comparing to RunI conditions, the difference in the mass window is $\delta m$, which originates from dynamic clustering. The $\delta m$ is calculated as:

\begin{align*}
\delta m&=\sqrt{\Big(\frac{\partial m_{\tau}}{\partial \eta_\text{{strip}}}\cdot f(\pt^\text{{strip}})\Big)^{2}+\Big(\frac{\partial m_{\tau}}{\partial \phi_\text{{strip}}}\cdot g(\pt^\text{{strip}})\Big)^{2}}\\
\end{align*}
with:
\begin{align*}
\frac{\partial m_{\tau}}{\partial\eta_{strip}}&=\frac{P_{z}^{strip}\cdot E_{\tau}-E_{strip}\cdot P_{z}^{\tau}}{m_{\tau}}\\
\frac{\partial m_{\tau}}{\partial\phi_\text{{strip}}}&=\frac{-(P_{y}^{\tau}-P_{y}^\text{{strip}})\cdot P_{x}^\text{{strip}}+(P_{x}^{\tau}-P_{x}^\text{{strip}})\cdot P_{y}^\text{{strip}}}{m_{\tau}}
\end{align*}


\begin{table}[htp]
\caption{$\tau$ hadronic decay mode hypothesis signatures compatibility tests. The $m_{\tau}$ is required to be in the mass window }\label{tb:tauHdecayRecomass}
\begin{center}
\begin{tabular}{|c|c|}
\hline
Decay mode                                             & Mass window\\\hline
$\tau^{-}\to h^{-}\pi^{0} v_{\tau}$                       & $0.3-\delta m_{\tau}<m_{\tau}<1.3\cdot \sqrt{\pt/100}+\delta m_{\tau}$      \\\hline
$\tau^{-}\to h^{-}\pi^{0} \pi^{0}  v_{\tau}$       &  $0.4-\delta m_{\tau}<m_{\tau}<1.2\cdot \sqrt{\pt/100}+\delta m_{\tau}$   \\\hline
$\tau^{-}\to h^{-}h^{+}h^{-}v_{\tau}$                     & $0.8-\delta m_{\tau}<m_{\tau}<1.5+\delta m_{\tau}$   \\\hline
 \end{tabular}
\end{center}
\end{table}

In current algorithm, $\tau^{-}\to h^{-}h^{+}h^{-}v_{\tau}$ is not included because of the jet contamination. This hadronic $\tau$ decay mode composed of 4.8\% of total branching fraction. The $h^{-}\pi^{0}$ and $h^{-}\pi^{0}\pi^{0}$ are analyzed together, which is referred as $h^{-}\pi^{0}$.

In the analysis with 2016 datasets, the MVA based $\tau$ isolation variable is used, which keeps high identification efficiency while maintains relatively low fake rate compared with cut based discriminator. A Boosted Decision Tree(BDT) has been used in the training of the isolation variable. In the BDT method, the isolation variable shows a good distinguishing power against jets. Various variables have been used as BDT inputs. The variables are isolation variable($I_{\tau}$), impact parameters from the highest $\pt$ track of $\tau_{h}$ candidate, $\tau_{h}$ decay mode information, shape variables like $\Delta R$, $\Delta \eta$, $\tau$ lifetime information and photon electron multiplicity. More details about the exact variables that are used are discussed in~\cite{TauRecoandIDRunII,TauReconstuction}. The BDT method uses these variables to distinguishing $\tau_{h}$ dacay from jets, which can be the decay products from quarks or gluons.  

The BDT method is also used in the tau discriminating again electron training. The algorithm utilizes the variables that are sensitive to the energy deposit in ECAL and HCAL, the electron bremsstrahlung, overall particle multiplicity and the difference in electromagnetic and hadronic showers. A detail list of these variables can be find in~\cite{TauRecoandIDRunII,TauReconstuction}.

Tau leptons from signal events can be misidentifed by muons, especially in $\tau_{h}$ decay mode $h^{\pm}$. The tau against muon discriminant is set by checking if there are signals in the muon system within $\Delta R=0.3$ of the $\tau_{h}$ direction or if the energy sum from ECAL and HCAL is less than 20$\%$ of the total $\tau$ energy. If less than two hits are found in the muon system, then it passes the loose working point. If no hits are found in the muon system, then this is the tight working point. 

\subsection{Jet reconstruction}
Jets are produced in the hadronic processes involving quarks or gluons. In the p-p collision, jet involves in most of the processes. Constructing jet properly is crucial and difficult. 

The Anti-$k_{t}$ jet clustering algorithm is used in CMS for the jet reconstruction. The algorithm starts by introducing the distance parameters $d_{ij}$ and $d_{iB}$ as following,

\begin{align*}
d_{ij}&=min(k_{ti}^{2p},k_{tj}^{2p})\frac{\Delta_{ij}^{2}}{R^{2}}\\
d_{iB}&=k_{ti}^{2p}
\end{align*}

The $d_{ij}$ is the distance between the particle and the pseudojet. The $\Delta_{ij}$ is the difference of rapidity and azimuth between entry i and entry j, $\Delta_{ij}^{2}=(\eta_{i}-\eta_{j})^{2}+(\phi_{i}-\phi_{j})^{2}$. The R is a radius parameter. The $k_{ti}$ and $k_{tj}$ stand for the momentum of the entries respectively. The p is a parameter used to specify jet construction algorithms.  For Anti-$k_{t}$, the parameter p is set as p=-1. The $d_{iB}$ is the distance between entry i and the beam. If the parameter p is set for other values, for example p=1 or 0, then the algorithm is the $k_t$~\cite{ktalgo} or Cambridge/Aachen jet reconstruction algorithm~\cite{Aachenjetalgo}.  In the Anti-$k_{t}$ algorithm, assuming in one event, there are a couple of hard particles with high momentum, $k_{t1}$, $k_{t2}$ and so on, also large numbers of soft ones around. Starting from $k_{t1}$ as an example, if $d_{1j}$ is smaller, then entry j combined with entry 1, if $d_{1B}$ is smaller, then entry 1 is set as a jet and removed from the list. The soft entries tend to cluster around the high momentum entries in the range $\Delta_{ij}= R$, if there is no other hard entry around. If two hard entries are within the distance R, then the two entries are clustered into a single entry. In this case, if $k_{1}\gg k_{2}$, then the center is more closed to jet 1. If $k_{1}\sim k_{2}$, the boundary between to two jets is defined by $\Delta R_{1b}/k_{t1}=\Delta_{2b}/k_{t2}$. The jet clustering continues until all of the jets are clustered in the events. 

The jet energy is corrected to have the correct energy scale.  The correction goes through a couple of steps~\cite{jetenergycorrection}. The major corrections are derived from simulated samples and the residual corrections for the different responses between MC and data samples are from data-driven methods. 

Pileup events can increase the measured jet energy, especially in LHC Run II, the number of pileup per event doubled. Two types of pileup affect the performance the most, the in-time pileup(IT PU) and the out-of time pileup(OOT PU). The IT PU refers to the additional events produced by the proton-proton collision within the same bunch-crossing besides the primary hard collisions. The OOT PU refers to the events that produced in previous bunch crossing or subsequent ones that affect current bunch. The OOT PU can be mitigated by exploring the timing window and the pulse shape of the calorimeter. Charged hadrons from IT PU in CMS are removed with charged-hadron subtraction(CHS) algorithm in CMS. Tracks with the vertexes that are identified from PU with charged particles are removed. The CHS removes around 50\% of the IT PU within the tracker coverage region. There are also soft jets from pileup interaction. These jets are usually in low energy range and affect the JES by overlapping with the hard jets. The multivariate analysis(MVA) with inputs from jet shape and jet constitution information can remove more than 90\% of pileup jets. This MVA ID is referred as PUJetID~\cite{PU_jetID}. After rejecting the charged particle jets and soft jets from pileup, a jet area method~\cite{FastJetalso} is used to further eliminate the effects from PU. In this method, an estimated energy density brought in by the PU and the effective area of jet are used to calculate the offset energy. After the PU correction, simulated response corrections are performed with QCD multijet sample. A matching between particle-level jet and reconstructed jet is performed. The correction is performed with the anti-$k_{T}$ jets with the distance parameter R=0.5 in $\pt$ and $
\eta$ distribution and checked with jets corresponding to R in range 0.3 to 1.0. Following the simulated response corrections, the remaining residual corrections are small which are derived with data-based methods and applied to data samples.


The B jet is a main component in $t\bar{t}$ process. The identification of b jet is important to the analysis involves $t\bar{t}$. In CMS,  a combined secondary vertex method(CSV) is used in the identification of b jet. The CSV method utilizes multivariable techniques to identify b jet~\cite{BTV-16-002}. B jets are from the hadronization of b quarks. B hadrons are relatively heavy, around 5-6 GeV, with high decay multiplicity, relatively high momentum decay products and relatively wide decay core compared with hadrons from light quarks. B hardons have long lifetime($ct\approx450$ um) which give a traveling distance $\approx5$ mm at the energy of 70 GeV. Exploring the property of the secondary vertex is used in the identification algorithm. In each of the jets, at least two tracks presenting in an angular distance $\Delta R <0.3$ is required. The jet with a combined mass of two tracks compatible with $k_{s}^{0}$ is rejected to reduce the contamination. A number of variables are used as MVA inputs in the identification. Details can be referred in~\cite{BTV-16-002}.  The MVA method combines the input variables into one discriminant variable to identify b jet.



\subsection{Missing transverse momentum}
The missing transverse momentum(MET) is defined as the sum $\pt$ of un-detected process in an event. In CMS, the particle flow MET is widely used and the MET can be expressed as $\vec{\slashed{E}}_{T}=-\sum \vec{p}_{T}$, in which the sum is over the observed PF particles. The magnitude of MET can be affected by various resources, for example, the in efficiency of tracker, the thresholds on calorimeter and the asymmetry in detector response. The propagation of JEC to MET can reduce the bias. The corrected MET can be expressed as
  
\begin{align*}
\vec{\slashed{E}}_{T}^{corr}=\vec{\slashed{E}}_{T}-\sum_{jets}(\vec{p}_{T,jet}^{~corr}-\vec{p}_{T,jet})
\end{align*}

The sum is over the jets with electromagnetic fraction below 0.9 and corrected $\pt>10$ GeV. Further correction on effect of PU on MET is derived with charged particles associated with PU vertexes, $\vec{v}=\sum_{charged}\vec{p}_{T}$. The correction is $f(\vec{v})\vec{v}$, in which factor $f(\vec{v})=c_{1}(1.0+\textrm{erf}(-c_{2}|\vec{v}|^{c_{3}}))$. the coefficients in $f(\vec{v})$ are estimated from fitting the MC minimum bias events. The PU effect corrected MET can be expressed as 
\begin{align*}
\vec{\slashed{E}}_{T}^{corr}=\vec{\slashed{E}}_{T}-\sum_{PU}f(\vec{v})\vec{v}
\end{align*}

The observed $\slashed{E}_{T}$ asymmetry in $\phi$ shows approximately linear relationship with the number of reconstructed vertices. The correction is performed with $N_{vtx}$ separately in x and y axis. 

The collinear-mass($\mcol$) is the most important variable in LFV Higgs decay analysis, which is closely related to the MET. The Higgs boson is massive compared with the leptons($\Pe,\Pgm,\Pgt$), thus the decay products are boosted. In $\Hmuhad$ and $\Hehad$ analysis, $\Pgt$ decays hadronically. The neutrinos in $\Pgt$ decay products are highly Lorentz boosted and are considered collinear with $\Pgt$. The direction of $\Pgt$ and the projection of MET amplitude on $\vec{\Pgt}$ direction are used to approximate the direction and energy of the neutrinos. With this approximation and the visible mass which is the mass formed with $\Pe$-$\Pgt$ or $\Pgm$-$\Pgt$ without any approximation, the $\mcol$ can be derived as

\begin{align*}
\mcol&=M_{vis}\Big/\sqrt{x^{vis}_{\Pgt}}\\
x^{vis}_{\Pgt}&=p_{T}^{\vec{\Pgt}^{vis}}\Big/(p_{T}^{\vec{\Pgt}^{vis}}+p_{T}^{\Pnu,est})
\end{align*}

\section{Event simulation}
The Monte Carlo simulation is used widely from the detector related processes, event reconstruction to physics analysis. The generation of MC sample in the generator involves the following steps. 

In LHC, p-p collision, QCD processes can involve large momentum transferring, multiply final states and complex surrounding environment. MC generators start by calculating the related QCD cross section. This including the calculating the matrix-element, choosing parton distribution functions(PDFs) and possibly performing high order correction, followed by the parton showers. In a hard process, parton showers use the basic building blocks like $q\rightarrow qg$, $q\rightarrow gq$, $g\rightarrow gg$ and $g\rightarrow q\bar{q}$, iteratively showering from high energy to low energy, typically, for quarks and gluons in the order of 1 GeV, when they can not be treated as free particles anymore. In addition to the hard subprocesses and the associated parton showers, a real event consists more contributions. Typically more than one pair of partons interact in one collision. These multiple interactions are dealt with different models and affect the total scattering energy, the number of the particle in the hadronization stage, etc. Because of the color confinement, quarks and gluons forms hadrons after completing the parton shower, this is referred as hadronization. Similarly to the QCD processes, electromagnetic radiation is also taken into account the evolution according to the electric charge instead of the color. After the generation of events through the MC generators, the events are put into GEANT4~\cite{GEANT4} to complete the detector simulation.

%Defination of underlying event
%The combination of particle production from MPI (excluding the parton-parton scattering with the highest
%momentum transfer) and BBR interactions is commonly called the underlying event (UE)

